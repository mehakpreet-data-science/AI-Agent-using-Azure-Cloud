ğŸ¦ Banking Support Assistant with RAG + Azure AI
This project demonstrates how to build a banking-specific AI support assistant powered by Retrieval-Augmented Generation (RAG) and Azure AI. The assistant provides accurate, context-aware answers by combining domain knowledge with the reasoning power of large language models (LLMs).
ğŸ”¹ Key Features
Data Ingestion â†’ Stored domain-specific content (FAQs, policies, instructions) in Azure Storage.
Indexing â†’ Created structured and searchable indexes for efficient retrieval.
RAG Pipeline â†’ Integrated indexed data with an LLM in Azure AI Foundry, ensuring answers are grounded in bank-specific data.
Deployment â†’ Deployed the model and exposed it as an API for real-world usage.
Python Integration â†’ Built a simple support assistant interface in Python that customers can interact with (e.g., â€œHow do I update my phone number in the bank?â€).
ğŸ”¹ Tech Stack
Azure AI Foundry (LLM orchestration)
Azure Storage (data ingestion & management)
Python (assistant logic & integration)
REST API (deployment & service consumption)
ğŸš€ Example Use Case
Customer queries like:
â€œHow do I update my phone number in the bank?â€
are answered with bank-specific, policy-driven responses rather than generic LLM output.
