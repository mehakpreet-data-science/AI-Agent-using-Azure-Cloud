🏦 Banking Support Assistant with RAG + Azure AI
This project demonstrates how to build a banking-specific AI support assistant powered by Retrieval-Augmented Generation (RAG) and Azure AI. The assistant provides accurate, context-aware answers by combining domain knowledge with the reasoning power of large language models (LLMs).
🔹 Key Features
Data Ingestion → Stored domain-specific content (FAQs, policies, instructions) in Azure Storage.
Indexing → Created structured and searchable indexes for efficient retrieval.
RAG Pipeline → Integrated indexed data with an LLM in Azure AI Foundry, ensuring answers are grounded in bank-specific data.
Deployment → Deployed the model and exposed it as an API for real-world usage.
Python Integration → Built a simple support assistant interface in Python that customers can interact with (e.g., “How do I update my phone number in the bank?”).
🔹 Tech Stack
Azure AI Foundry (LLM orchestration)
Azure Storage (data ingestion & management)
Python (assistant logic & integration)
REST API (deployment & service consumption)
🚀 Example Use Case
Customer queries like:
“How do I update my phone number in the bank?”
are answered with bank-specific, policy-driven responses rather than generic LLM output.
